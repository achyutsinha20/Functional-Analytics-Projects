{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "bCRM_a-UitiA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Ii-rqggg4Vv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3G-YMC0iIHp",
        "outputId": "08f71a73-e75f-4180-a061-158c3e536144"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training = pd.read_csv('/content/drive/MyDrive/SYNERGEN Exercise_Train.csv')"
      ],
      "metadata": {
        "id": "8HiTzla5iZ2f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "8MPelSVji37H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training.tail(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "i1tedkO4ijvg",
        "outputId": "7ad30603-fd41-4145-d569-6156c57cc1d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           UNIQUE_ID LIST_OF_INGREDIENTS PREPARATION_METHOD MANUFACTURED_DATE  \\\n",
              "182  NopCApkw4nCCwQw                  X6                D10        2017-02-02   \n",
              "183  hntvWJULUiJSybI  X1, X2, X3, X4, X5         D2, D1, D3        2017-02-05   \n",
              "184   w7WNrNenF4h9C5  X1, X2, X3, X4, X5         D1, D2, D3        2017-12-31   \n",
              "\n",
              "    MANUFACTURED_LOCATION  QUANTITY  APPETIZING_COLOR  ATTRACTIVE_PACKAGING  \\\n",
              "182                    Y1        50                 0                     1   \n",
              "183                    Y3       150                 0                     1   \n",
              "184                    Y1        50                 1                     1   \n",
              "\n",
              "    SUBMISSION_DATE QUALITY_ASSURANCE_ENTITY  RESPONSE  \n",
              "182      2017-02-03                       Z1         0  \n",
              "183      2017-02-06                       Z1         0  \n",
              "184      2018-01-01                       Z1         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e429cf1f-81a1-49c7-99ac-91053a50e6b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIQUE_ID</th>\n",
              "      <th>LIST_OF_INGREDIENTS</th>\n",
              "      <th>PREPARATION_METHOD</th>\n",
              "      <th>MANUFACTURED_DATE</th>\n",
              "      <th>MANUFACTURED_LOCATION</th>\n",
              "      <th>QUANTITY</th>\n",
              "      <th>APPETIZING_COLOR</th>\n",
              "      <th>ATTRACTIVE_PACKAGING</th>\n",
              "      <th>SUBMISSION_DATE</th>\n",
              "      <th>QUALITY_ASSURANCE_ENTITY</th>\n",
              "      <th>RESPONSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>NopCApkw4nCCwQw</td>\n",
              "      <td>X6</td>\n",
              "      <td>D10</td>\n",
              "      <td>2017-02-02</td>\n",
              "      <td>Y1</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-02-03</td>\n",
              "      <td>Z1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>hntvWJULUiJSybI</td>\n",
              "      <td>X1, X2, X3, X4, X5</td>\n",
              "      <td>D2, D1, D3</td>\n",
              "      <td>2017-02-05</td>\n",
              "      <td>Y3</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-02-06</td>\n",
              "      <td>Z1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>w7WNrNenF4h9C5</td>\n",
              "      <td>X1, X2, X3, X4, X5</td>\n",
              "      <td>D1, D2, D3</td>\n",
              "      <td>2017-12-31</td>\n",
              "      <td>Y1</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>Z1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e429cf1f-81a1-49c7-99ac-91053a50e6b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e429cf1f-81a1-49c7-99ac-91053a50e6b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e429cf1f-81a1-49c7-99ac-91053a50e6b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT9LyxQyindv",
        "outputId": "744a3ff6-362c-48c9-9e9d-283f34b1154f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['UNIQUE_ID', 'LIST_OF_INGREDIENTS', 'PREPARATION_METHOD',\n",
              "       'MANUFACTURED_DATE', 'MANUFACTURED_LOCATION', 'QUANTITY',\n",
              "       'APPETIZING_COLOR', 'ATTRACTIVE_PACKAGING', 'SUBMISSION_DATE',\n",
              "       'QUALITY_ASSURANCE_ENTITY', 'RESPONSE'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use tabular data in Machine Learning (usually, load data as CSV files.) If we take a single cell from the 'LIST OF INGREDIENTS' and PREPARATION METHOD, each cell represents a list of properties. As a result, we must process and create colours to represent those properties."
      ],
      "metadata": {
        "id": "0PeTZScrjQUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#identifying distinctive properties in those two columns\n",
        "\n",
        "def find_unique_items(series):\n",
        "    unique = set()\n",
        "    for elements in series.iteritems():\n",
        "        ingre = elements[1]\n",
        "        for element in ingre.split(','):\n",
        "            unique.add(element.strip())\n",
        "    return unique"
      ],
      "metadata": {
        "id": "Hav5NdGSirFW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Unique values in LIST_OF_INGREDIENTS: {}'.format(find_unique_items(training['LIST_OF_INGREDIENTS'])))\n",
        "print('Unique values in PREPARATION_METHOD: {}'.format(find_unique_items(training['PREPARATION_METHOD'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY9UHgmmjecX",
        "outputId": "d5cda1d2-a157-4350-8985-d796b0f1ffcd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in LIST_OF_INGREDIENTS: {'X8', 'X1', 'X6', 'X2', 'X3', 'X9', 'X10', 'X5', 'X7', 'X4'}\n",
            "Unique values in PREPARATION_METHOD: {'D10', 'D8', 'D3', 'D5', 'D15', 'D2', 'D11', 'D4', 'D1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, those list of properties in LIST_OF_INGREDIENTS and PREPARATION_METHOD\n",
        "# replaces with a set of columns\n",
        "def ingregient_extractor(x, ingredient):\n",
        "    for element in x.split(','):\n",
        "        y = element.strip()\n",
        "        if y == ingredient:\n",
        "            return 1\n",
        "    return 0"
      ],
      "metadata": {
        "id": "R6SBR4JUjh4-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training['X_1'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X1',))\n",
        "training['X_2'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X2',))\n",
        "training['X_3'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X3',))\n",
        "training['X_4'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X4',))\n",
        "training['X_5'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X5',))\n",
        "training['X_6'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X6',))\n",
        "training['X_7'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X7',))\n",
        "training['X_8'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X8',))\n",
        "training['X_9'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X9',))\n",
        "training['X_10'] = training['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X10',))\n",
        "\n",
        "training['D_1'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D1',)) \n",
        "training['D_2'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D2',)) \n",
        "training['D_3'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D3',)) \n",
        "training['D_4'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D4',)) \n",
        "training['D_5'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D5',)) \n",
        "\n",
        "training['D_8'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D8',)) \n",
        "training['D_10'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D10',)) \n",
        "training['D_11'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D11',)) \n",
        "training['D_15'] = training['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D15',)) "
      ],
      "metadata": {
        "id": "n2LvznAKjroY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "LDiwlDrdj6qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, we drop LIST_OF_INGREDIENTS and PREPARATION_METHOD\n",
        "del training['LIST_OF_INGREDIENTS']\n",
        "del training['PREPARATION_METHOD']"
      ],
      "metadata": {
        "id": "-Ds5glPajuqv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.groupby('RESPONSE').count()['UNIQUE_ID']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91W5ZBHWjyh2",
        "outputId": "6d3a0786-4aee-4d82-c193-6498f728a145"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RESPONSE\n",
              "0    90\n",
              "1    95\n",
              "Name: UNIQUE_ID, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding categorical data create our training features"
      ],
      "metadata": {
        "id": "Kr6_S2kRkC4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_features = pd.concat([training[['X_1', 'X_2', 'X_3', 'X_4', 'X_5', \n",
        "                                         'X_6', 'X_7', 'X_8', 'X_9', 'X_10', \n",
        "                                         'D_1', 'D_2', 'D_3', 'D_4', 'D_5', \n",
        "                                         'D_8', 'D_10', 'D_11', 'D_15',\n",
        "                                         'QUANTITY', 'ATTRACTIVE_PACKAGING']], \n",
        "                               pd.get_dummies(training[['MANUFACTURED_LOCATION']]),\n",
        "                               pd.get_dummies(training[['QUALITY_ASSURANCE_ENTITY']])], \n",
        "                               axis=1)"
      ],
      "metadata": {
        "id": "yH_uBPZcj1vW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Yu6ihQ-keVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Logistic Regression and Random Forest for building our model and hypertuning "
      ],
      "metadata": {
        "id": "IH-KGM1JkNEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "X_train = training_features.values\n",
        "y_train = training['RESPONSE'].values\n",
        "\n",
        "folds = KFold(n_splits=3, shuffle=True)\n",
        "cv_accuracies = []\n",
        "for trining_idx, testing_idx in folds.split(X_train):\n",
        "    X_train_cv = X_train[trining_idx]\n",
        "    y_train_cv = y_train[trining_idx]\n",
        "    \n",
        "    X_test_cv = X_train[testing_idx]\n",
        "    y_test_cv = y_train[testing_idx]\n",
        "    \n",
        "    logistic_regression = LogisticRegression()\n",
        "    logistic_regression.fit(scale(X_train_cv), y_train_cv)\n",
        "    y_predict_cv = logistic_regression.predict(scale(X_test_cv))\n",
        "    current_accuracy = accuracy_score(y_test_cv, y_predict_cv)\n",
        "    cv_accuracies.append(current_accuracy)\n",
        "    print('cross validation accuracy: {}'.format(current_accuracy))\n",
        "    \n",
        "print( '---------------------------------------')\n",
        "print( 'average corss validation accuracy: %f' %(sum(cv_accuracies)/len(cv_accuracies)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckz2eez1kI4H",
        "outputId": "1aca0f55-5752-4d55-acf7-8ac4c2469f38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross validation accuracy: 0.8870967741935484\n",
            "cross validation accuracy: 0.6774193548387096\n",
            "cross validation accuracy: 0.7049180327868853\n",
            "---------------------------------------\n",
            "average corss validation accuracy: 0.756478\n",
            "CPU times: user 122 ms, sys: 21.1 ms, total: 143 ms\n",
            "Wall time: 389 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X_train = training_features.values\n",
        "y_train = training['RESPONSE'].values\n",
        "\n",
        "folds = KFold(n_splits=3, shuffle=True)\n",
        "cv_accuracies = []\n",
        "for trining_idx, testing_idx in folds.split(X_train):\n",
        "    X_train_cv = X_train[trining_idx]\n",
        "    y_train_cv = y_train[trining_idx]\n",
        "    \n",
        "    X_test_cv = X_train[testing_idx]\n",
        "    y_test_cv = y_train[testing_idx]\n",
        "    \n",
        "    random_forest = RandomForestClassifier(n_estimators = 100)\n",
        "    random_forest.fit(scale(X_train_cv), y_train_cv)\n",
        "    y_predict_cv = random_forest.predict(scale(X_test_cv))\n",
        "    current_accuracy = accuracy_score(y_test_cv, y_predict_cv)\n",
        "    cv_accuracies.append(current_accuracy)\n",
        "    print( 'cross validation accuracy: %f' %(current_accuracy))\n",
        "\n",
        "    \n",
        "print('---------------------------------------')\n",
        "print('average corss validation accuracy: %f' %(sum(cv_accuracies)/len(cv_accuracies))) \n",
        "print( '---------------------------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlDEIG11kMtH",
        "outputId": "d62e8e5d-176b-4b2f-9c26-d4b4791842fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross validation accuracy: 0.822581\n",
            "cross validation accuracy: 0.790323\n",
            "cross validation accuracy: 0.770492\n",
            "---------------------------------------\n",
            "average corss validation accuracy: 0.794465\n",
            "---------------------------------------\n",
            "\n",
            "CPU times: user 825 ms, sys: 11.4 ms, total: 836 ms\n",
            "Wall time: 1.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Going ahead with random forest because it works better "
      ],
      "metadata": {
        "id": "YYd6zlSYksEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = training_features.values\n",
        "y_train = training['RESPONSE'].values\n",
        "random_forest = RandomForestClassifier(n_estimators = 100)\n",
        "random_forest.fit(scale(X_train_cv), y_train_cv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_RZspZNknA2",
        "outputId": "5ff91ea7-7a19-414c-f1fd-e2195cd60f73"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning the testing dataset\n",
        "# Next, we clean the testing dataset\n",
        "testing = pd.read_csv('/content/drive/MyDrive/SYNERGEN Exercise_Prediction.csv')\n",
        "\n",
        "testing['X_1'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X1',))\n",
        "testing['X_2'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X2',))\n",
        "testing['X_3'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X3',))\n",
        "testing['X_4'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X4',))\n",
        "testing['X_5'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X5',))\n",
        "testing['X_6'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X6',))\n",
        "testing['X_7'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X7',))\n",
        "testing['X_8'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X8',))\n",
        "testing['X_9'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X9',))\n",
        "testing['X_10'] = testing['LIST_OF_INGREDIENTS'].apply(ingregient_extractor, args=('X10',))\n",
        "\n",
        "\n",
        "testing['D_1'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D1',)) \n",
        "testing['D_2'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D2',)) \n",
        "testing['D_3'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D3',)) \n",
        "testing['D_4'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D4',)) \n",
        "testing['D_5'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D5',)) \n",
        "\n",
        "testing['D_8'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D8',)) \n",
        "testing['D_10'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D10',)) \n",
        "testing['D_11'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D11',)) \n",
        "testing['D_15'] = testing['PREPARATION_METHOD'].apply(ingregient_extractor, args=('D15',)) \n",
        "\n",
        "del testing['LIST_OF_INGREDIENTS']\n",
        "del testing['PREPARATION_METHOD']\n",
        "\n",
        "testing_features = pd.concat([testing[['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', \n",
        "                                         'D_1', 'D_2', 'D_3', 'D_4', 'D_5', 'D_8', 'D_10', 'D_11', 'D_15',\n",
        "                                         'QUANTITY', 'ATTRACTIVE_PACKAGING']], \n",
        "                                         pd.get_dummies(testing[['MANUFACTURED_LOCATION']]),\n",
        "                                         pd.get_dummies(testing[['QUALITY_ASSURANCE_ENTITY']])], axis=1)"
      ],
      "metadata": {
        "id": "VNfnS7krk4CB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = testing_features.values\n",
        "output = random_forest.predict(X_test)\n",
        "unique_indices = training['UNIQUE_ID'].values\n",
        "for i, j in zip(output, unique_indices):\n",
        "    print('index: {} prediction: {}'.format(j, i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv4Ov-AKlG1F",
        "outputId": "bba5de16-3261-41e0-d808-918180948206"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index: monUvMmr95OP05e prediction: 0\n",
            "index: 1xbRcd2JbUuZ0IK prediction: 1\n",
            "index: 8FMJ6YMJYbTC4yp prediction: 0\n",
            "index: fuovowqPpCHv3W9 prediction: 0\n",
            "index: monUvMmr95OP05e prediction: 0\n",
            "index: monUvMmr95OP05e prediction: 1\n",
            "index: monUvMmr95OP05e prediction: 1\n",
            "index: monUvMmr95OP05e prediction: 0\n",
            "index: monUvMmr95OP05e prediction: 1\n",
            "index: monUvMmr95OP05e prediction: 0\n",
            "index: winhsDL92bKQS4x prediction: 1\n",
            "index: xWc5x0sOguKgkJa prediction: 1\n",
            "index: 8jE26hwkyWzOOpV prediction: 0\n",
            "index: j1KqeiH7KrzuW9N prediction: 1\n",
            "index: lBLYpZi7P5Fbs1N prediction: 0\n",
            "index: tossSzrrzX43iqu prediction: 0\n",
            "index: ZIIvtO5hcTg8Tg4 prediction: 1\n",
            "index: w7WNrNenF4h9C5 prediction: 1\n",
            "index: z8lmAhwtP3ehr63 prediction: 1\n",
            "index: QibP7kHXVqO8Ve7 prediction: 0\n",
            "index: SuNat7oTPLjWsXD prediction: 1\n",
            "index: 9KXp0XrXblr7bxy prediction: 0\n",
            "index: w7WNrNenF4h9C5 prediction: 0\n",
            "index: b8HQmdEN4W8VMfj prediction: 0\n",
            "index: Cb1ZysE3Vb0BmRc prediction: 1\n",
            "index: jbsQ6vrRg4FK2ea prediction: 1\n",
            "index: RcECLtfRYf0pIvi prediction: 0\n",
            "index: vUimrsgQNsFAl7s prediction: 0\n",
            "index: ySGmj9yzdQLoO6r prediction: 1\n",
            "index: mUxn2XVYf0BEp1n prediction: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key points:\n",
        "\n",
        "1. Learning from previous data is central to machine learning. The lack of data available for building the model greatly aids in generalising the model. So having more data helps to make better predictions. Unfortunately, this dataset only contains 200 data points. As a result, building a generalise model with such a small dataset is impossible.\n",
        "\n",
        "2. Even this such a small dataset and relatively simple algorithm, we managed to achieve just above 80 percent accuracy"
      ],
      "metadata": {
        "id": "QKcrW3KQlfXY"
      }
    }
  ]
}